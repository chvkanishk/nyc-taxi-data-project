"""
Complete pipeline runner
Bronze ‚Üí Silver ‚Üí Gold
"""

from pyspark.sql import SparkSession
from src.transformation.bronze_layer import BronzeLayer, create_spark_session
from src.transformation.silver_layer import SilverLayer
from src.transformation.gold_layer import GoldLayer
import os
from datetime import datetime


def run_complete_pipeline():
    """Run the complete medallion pipeline"""
    
    print("\n" + "="*70)
    print("üöÄ NYC TAXI DATA PIPELINE - COMPLETE RUN")
    print("="*70 + "\n")
    
    start_time = datetime.now()
    
    # Create Spark session
    print("1Ô∏è‚É£ Initializing Spark...")
    spark = create_spark_session()
    print("‚úÖ Spark initialized\n")
    
    # BRONZE LAYER
    print("2Ô∏è‚É£ BRONZE LAYER: Loading raw data...")
    bronze = BronzeLayer(spark)
    
    months = ["2024-01", "2024-02", "2024-03"]
    for month in months:
        source_file = f"data/raw/yellow_tripdata_{month}.parquet"
        if os.path.exists(source_file):
            bronze.load_raw_to_bronze(source_file, month)
    
    bronze.show_bronze_stats()
    bronze_df = bronze.read_bronze()
    print("‚úÖ Bronze layer complete\n")
    
    # SILVER LAYER
    print("3Ô∏è‚É£ SILVER LAYER: Cleaning and validating...")
    silver = SilverLayer(spark)
    silver_df = silver.transform_bronze_to_silver(bronze_df)
    silver.save_silver(silver_df)
    print("‚úÖ Silver layer complete\n")
    
    # GOLD LAYER
    print("4Ô∏è‚É£ GOLD LAYER: Creating analytics tables...")
    gold = GoldLayer(spark)
    gold_tables = gold.create_all_gold_tables(silver_df)
    print("‚úÖ Gold layer complete\n")
    
    # SUMMARY
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    print("\n" + "="*70)
    print("üéâ PIPELINE COMPLETE!")
    print("="*70)
    print(f"‚è±Ô∏è  Duration: {duration:.1f} seconds")
    print(f"üìä Bronze records: {bronze_df.count():,}")
    print(f"üìä Silver records: {silver_df.count():,}")
    print(f"üíé Gold tables created: {len(gold_tables)}")
    print("="*70 + "\n")
    
    # Cleanup
    spark.stop()


if __name__ == "__main__":
    run_complete_pipeline()